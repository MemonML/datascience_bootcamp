{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MemonML/datascience_bootcamp/blob/main/day21_ANN_Artificial_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRVsAwb1fioQ"
      },
      "source": [
        "*Logistic Regression*\n",
        "- 1/ (1+e(^ theta * x))\n",
        "- Find parameters that minimize the cost function\n",
        "- Cost_function = actual - predicted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpePq0DOga_4"
      },
      "source": [
        "# Traditional Machine Learning algorithm cannot perform good on complex dataset thats why we use ANN.\n",
        "\n",
        "# To build Non-Linear boundary we add polynomials, it will increase the features size\n",
        "- incrase the complexity\n",
        "- degrade the performance\n",
        "\n",
        ">> all algo knn, logic, nb ,dtc, rf,svm apply on huge dataset and also apply ANN and compare which give good result. apple analysis\n",
        "\n",
        ">> Increase features size traditional algorithm performance will start to decrease\n",
        "\n",
        "# Solution to all above problem is Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaIP5zbQjlDJ"
      },
      "source": [
        "#ANN\n",
        "- Basic building block\n",
        "-- neurons\n",
        "-- i/p layer\n",
        "-- hidden layer\n",
        "-- o/p layer\n",
        "- All neurons conneted through **weights**\n",
        "\n",
        "# Acitvation function\n",
        "- limit the value\n",
        "- introduce linearity\n",
        "> what activation function need to used ?\n",
        "\n",
        "# Bias (Wo)\n",
        "- h(x)= 0x1 + 0x2\n",
        "\n",
        "\n",
        "# Sop (w1*x1 + w2 * x2)\n",
        "\n",
        "give line\n",
        "\n",
        "# Activation fucntion give single point multiple acitvation fucntion gives decision boundaries\n",
        "\n",
        "# More complex boundary add more hiddern layers but if we add more hidden layer it can be overfit.\n",
        "# output layer( Ok)\n",
        "\n",
        "# target output ---> Single neurons (Sales --- ouput only give 1 value how? it varies every time we give the output as we give different output\n",
        "\n",
        "# Backpropagation\n",
        "- change weights according to weights\n",
        "\n",
        "\n",
        "# How to update error?\n",
        "- Take batch and find overall error and update the weights\n",
        "- why we take batch?\n",
        "- 2 reasons:\n",
        "-- to decrease complexity\n",
        "-- when we take batch , find error ---> update the weights.\n",
        "# Loss functions\n",
        "- Same as error\n",
        "- actual - predicted\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzqt_5N7v--g"
      },
      "source": [
        "# Back Propagation\n",
        "- Initialize the weights\n",
        "-\n",
        "- forward pass\n",
        "- back propagate\n",
        "- update the wights\n",
        "- termitate condition ( no. of epocs or desired error value )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH1sq5FkxAt-"
      },
      "source": [
        "# Gradient Descent\n",
        "- Optimization algorithm\n",
        "- To find optimal points\n",
        "- Learning rate(a) alpha --> how it quickly converge\n",
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sj46wwzyTAY"
      },
      "source": [
        "#Error\n",
        "- Find rate of change\n",
        "- Err= prd*(1-pred)(Actu- pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpvo-U3UzZs5"
      },
      "source": [
        "# Small networks\n",
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG5ul_sG0gRH"
      },
      "source": [
        "# MNist 786\n",
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoISUlVt8eRw"
      },
      "source": [
        "# First Deep Learning Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUKAsBzP85ug"
      },
      "source": [
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Cyaun_b8u2R"
      },
      "source": [
        "#Steps\n",
        "- 1.Define the models\n",
        "-- layers, neurons, optimizer\n",
        "--\n",
        "- Squential\n",
        "-- layer by layer right to left\n",
        "- Dense\n",
        "-- Fully connected layers\n",
        "- jobli ---to save model\n",
        "- time--- > how time taken to train the model\n",
        "\n",
        "\n",
        "# In neural networks data shoul be normalized\n",
        "-\n",
        "\n",
        "# Relu- rectified linear unit (limit the ouput of neurons and introduce the non-linearity )\n",
        "- Remove the negative value\n",
        "- Retain the positive value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYu2ehAZ-9lv"
      },
      "source": [
        "#Optimizer\n",
        "- find local minima\n",
        "- in this case we use \"adam\" optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA9yaHfx_Ysi"
      },
      "source": [
        "# Loss\n",
        "- Err= prd*(1-pred)(Actu- pred)\n",
        "- sparse_ catagorical_crossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht1H4m7uD3ro"
      },
      "source": [
        "# Hyper- parameter\n",
        "- batch size (divide 60k image into 64. 64 batches will be made then it forward pass it to the network randomly(64 batches of 60k)\n",
        "- optimizer\n",
        "- No. of neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc3uA-6SdY3B"
      },
      "source": [
        "#Feature Engineering\n",
        "- Derivie new features from the existing featrues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBlsLvZKfYiH"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTLmZsChfYkq"
      },
      "source": [
        "# if input layers and first hidden layers have same neurons then model becomes overfit\n",
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDEt1x1rfYgf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obBY5ULFfXwo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import joblib\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRyT39Qm5lfz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZtZaqIqFmPe"
      },
      "outputs": [],
      "source": [
        "# # Load and the prepare the MNIST dataset to be acceptable for the model\n",
        "# (x_train,y_train),(x_test,y_test)= mnist.load_data()\n",
        "# x_train=x_train.reshape(-1,784)/255.0\n",
        "# x_test=x_test.reshape(-1,784)/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOEOShvA5N7h"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "digits= datasets.load_digits()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY2vVS-05QTx"
      },
      "outputs": [],
      "source": [
        "xx,yy=digits.data,digits.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OF2LdSuB5g9z"
      },
      "outputs": [],
      "source": [
        "xx_train, xx_test, yy_train, yy_test = train_test_split(xx, yy, test_size=0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtTpR61QGDqr",
        "outputId": "af529ecf-308e-414c-a729-da73cff2de16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1437, 64) (360, 64) (1437,) (360,)\n"
          ]
        }
      ],
      "source": [
        "print(xx_train.shape, xx_test.shape, yy_train.shape, yy_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G84h4f9sGDnT"
      },
      "outputs": [],
      "source": [
        "# Build a simple ANN architecture (input layer = 1, hidden layers= 2, output layer= 1)\n",
        "cnnmodel= Sequential([\n",
        "    Dense(128,activation=\"relu\",input_shape=(64,)),\n",
        "\n",
        "    Dense(64,activation=\"relu\"),\n",
        "    Dense(32,activation=\"relu\"),\n",
        "\n",
        "    Dense(10,activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBXose4NGDkc"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "cnnmodel.compile(optimizer=\"adam\",loss='sparse_categorical_crossentropy',metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "snx2U7V4Hn_N",
        "outputId": "6e78cefa-3184-4a8e-8d97-09eafb5aa5e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 2s 18ms/step - loss: 1.9155 - accuracy: 0.4530 - val_loss: 0.8231 - val_accuracy: 0.7556\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5126 - accuracy: 0.8664 - val_loss: 0.3502 - val_accuracy: 0.9056\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.2547 - accuracy: 0.9360 - val_loss: 0.2344 - val_accuracy: 0.9361\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.1686 - accuracy: 0.9589 - val_loss: 0.2070 - val_accuracy: 0.9361\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9624 - val_loss: 0.2054 - val_accuracy: 0.9389\n"
          ]
        }
      ],
      "source": [
        "#Train the model\n",
        "s= time.time()\n",
        "cnnmodel.fit(xx_train,yy_train,epochs=5, batch_size= 64, validation_data=(xx_test,yy_test) )\n",
        "E= time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf5FxjN0IEtm",
        "outputId": "2a120d2e-eff2-4aa6-9d0d-87abe456759c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9389\n",
            "Test Accuracy: 0.9388889074325562\n",
            "Total time take while Training  2.6081812381744385\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc= cnnmodel.evaluate(xx_test,yy_test)\n",
        "#joblib.dump(cnnmodel,\"cnnmodel.joblib\" )\n",
        "print(f\"Test Accuracy: {test_acc}\")\n",
        "print(\"Total time take while Training \",E-s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s0Gt4ilm6pc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}